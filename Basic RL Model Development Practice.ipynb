{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Short Game To See How An Agent Learns to Attain A Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a simple game where a player will itself learn to jump from one state to another. The Dictionary 'MAPS'\n",
    "## gives from which states to which states can a person jump to. The Dictionary 'REWARDS' gives reward for each\n",
    "## state. The Dictionary policy will give us the policy learnt by our player after making 'STEPS' trials. Initial\n",
    "## policy is set to 0 for each state (0 state does not exist) so that our player would update the policy randomly\n",
    "## at first but then over many trials, it will self learn to decide what's best for it. The code below will take \n",
    "## only 1 input : The number of trials or steps you want for it to learn. You can also change the code according\n",
    "## to yourself to create new states(more complex). It shows that with increase in 'STEPS', our agent performs \n",
    "## better everytime. This code will print the policy after every iteration to visualise updates and current score.\n",
    "## At the end it will also show the percentage times the agent went to a negative reward state. You would see that \n",
    "## as you increase 'STEPS', this percentage will go down. YOU CAN COPY THE CODE TO TRY IT OUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***  HELLO HUMAN! GAME WILL START SOON.. PLEASE ENTER THE NUMBER OF TRIALS  ***\n",
      "142\n",
      "\n",
      " GAME STARTS\n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0} Current Score : 20 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 1, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0} Current Score : -80 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 5, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0} Current Score : -180 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 5, 2: 0, 3: 0, 4: 1, 5: 2, 6: 0} Current Score : -190 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 5, 2: 2, 3: 0, 4: 1, 5: 2, 6: 0} Current Score : -177 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 0, 4: 1, 5: 2, 6: 0} Current Score : -164 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 0, 4: 1, 5: 2, 6: 3} Current Score : -64 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : -69 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 31 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 26 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 126 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 121 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 221 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 216 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 316 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 311 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 411 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 406 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 506 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 501 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 601 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 596 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 696 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 691 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 791 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 786 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 886 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 3} Current Score : 881 \n",
      "\n",
      "Policy Updated !\n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 981 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 994 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1094 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1107 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1207 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1220 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1320 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1333 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1433 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1446 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1546 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1559 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1659 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1672 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1772 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1785 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1885 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1898 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 1998 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2011 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2111 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2124 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2224 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2237 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2337 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2350 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2450 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2463 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2563 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2576 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2676 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2689 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2789 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2802 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2902 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 2915 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3015 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3028 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3128 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3141 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3241 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3254 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3354 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3367 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3467 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3480 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3580 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3593 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3693 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3706 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3806 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3819 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3919 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 3932 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4032 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4045 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4145 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4158 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4258 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4271 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4371 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4384 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4484 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4497 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4597 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4610 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4710 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4723 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4823 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4836 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4936 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 4949 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5049 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5062 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5162 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5175 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5275 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5288 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5388 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5401 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5501 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5514 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5614 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5627 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5727 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5740 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5840 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5853 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5953 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 5966 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6066 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6079 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6179 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6192 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6292 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6305 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6405 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6418 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6518 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6531 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6631 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6644 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6744 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6757 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6857 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6870 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6970 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 6983 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 7083 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 7096 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 7196 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 7209 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 7309 \n",
      "\n",
      "Current Policy : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} Current Score : 7322 \n",
      "\n",
      "****************************************************************\n",
      "\n",
      "Game ended after 142 steps with score 7322 \n",
      "\n",
      "Percent Of Times when negative reward was encountered 9.859154929577464 %\n",
      "\n",
      "Policy Learned After 142 trials : {1: 5, 2: 6, 3: 6, 4: 1, 5: 2, 6: 2} \n",
      "\n",
      "GAME OVER !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import *\n",
    "\n",
    "policy = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
    "reward = {1:-100, 2:13, 3:-5, 4:20, 5:-10, 6:100}\n",
    "maps = {1:[1,2,5,6], 2:[1,2,5,6], 3:[2,3,4,6], 4:[1,6,4,5],5:[1,2,4,5],6:[3,5,2]}\n",
    "\n",
    "\n",
    "def action(x) :\n",
    "    rand_idx = randint(0,len(maps[x])-1)\n",
    "    return maps[x][rand_idx]\n",
    "\n",
    "\n",
    "def rewards(x) :\n",
    "    return reward[x];\n",
    "\n",
    "\n",
    "def testgame() :\n",
    "    print(\"***  HELLO HUMAN! GAME WILL START SOON.. PLEASE ENTER THE NUMBER OF TRIALS  ***\")\n",
    "    steps = input()\n",
    "    print(\"\\n GAME STARTS\\n\")\n",
    "    steps = int(steps)\n",
    "    steps2 = steps\n",
    "    score = 0\n",
    "    x = randint(1,6)\n",
    "    policycopy = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
    "    pos = 0\n",
    "    negs = 0\n",
    "    while(steps>0):\n",
    "        score+=rewards(x)\n",
    "        if(rewards(x)<0):\n",
    "            negs+=1\n",
    "        else:\n",
    "            pos+=1\n",
    "        y = action(x)\n",
    "        if policy[x]==0 :\n",
    "            policy[x] = y\n",
    "        else :\n",
    "            if rewards(y)>rewards(policy[x]):\n",
    "                policy[x] = y\n",
    "        if policy[x]!=policycopy[x] :\n",
    "            print(\"Policy Updated !\\n\")\n",
    "        policycopy[x] = policy[x]\n",
    "        x = policy[x]\n",
    "        steps-=1;\n",
    "        print(\"Current Policy :\",policy,\"Current Score :\",score,\"\\n\")\n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(\"Game ended after\",steps2,\"steps with score\",score,\"\\n\")\n",
    "    print(\"Percent Of Times when negative reward was encountered\",(negs/steps2)*100.0,\"%\\n\")\n",
    "    print(\"Policy Learned After\",steps2,\"trials :\",policy,\"\\n\")\n",
    "    print(\"GAME OVER !\\n\")\n",
    "    \n",
    "    \n",
    "testgame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
